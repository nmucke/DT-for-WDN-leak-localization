training_params:
  num_epochs: 2000
  batch_size: 64
  kernel_regu: 1.0e-2
  kernel: 'multiscale'

model_params:
  architecture: 'dense'
  type: 'SupervisedWAE'
  encoder:
    latent_dim: 16
    state_dim: 65
    hidden_neurons: [64, 32, 16]
  decoder:
    latent_dim: 16
    state_dim: 65
    hidden_neurons: [16, 32, 64]
  #encoder:
  #    latent_dim: 16
  #    state_dim: 65
  #    embed_dim: 2
  #    num_heads: 1
  #    hidden_neurons: [32, 16]
  #decoder:
  #    latent_dim: 16
  #    state_dim: 65
  #    embed_dim: 2
  #    num_heads: 1
  #    hidden_neurons: [16, 32]
  #    pars_dims: [34, 24]
  name: 'SupervisedWAE'

optimizer_params:
  type: 'Adam'
  encoder_args:
    lr: 5.0e-4
    weight_decay: 1.0e-10
  decoder_args:
    lr: 5.0e-4
    weight_decay: 1.0e-10

scheduler_params:
  type: CosineWarmupScheduler
  args:
    warmup: 50 
    max_iters: 500

data_params:
  num_pipes: 34
  num_nodes: 31
  num_time_steps: 24
  include_leak_area: False

early_stopping_params:
  patience: 30



